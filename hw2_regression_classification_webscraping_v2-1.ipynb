{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data-X Spring 2018: Homework 02\n",
    "\n",
    "### Regression, Classification, Webscraping\n",
    "\n",
    "**Authors:** Sana Iqbal (Part 1, 2, 3), Alexander Fred-Ojala (Extra Credit)\n",
    "\n",
    "\n",
    "In this homework, you will do some exercises with prediction-classification, regression and web-scraping.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Data:\n",
    "__Data Source__:\n",
    "Data file is uploaded to bCourses and is named: __Energy.csv__\n",
    "\n",
    "The dataset was created by Angeliki Xifara ( Civil/Structural Engineer) and was processed by Athanasios Tsanas, Oxford Centre for Industrial and Applied Mathematics, University of Oxford, UK).\n",
    "\n",
    "__Data Description__:\n",
    "\n",
    "The dataset contains eight attributes of a building (or features, denoted by X1...X8) and response being the heating load on the building, y1. \n",
    "\n",
    "* X1\tRelative Compactness \n",
    "* X2\tSurface Area \n",
    "* X3\tWall Area \n",
    "*  X4\tRoof Area \n",
    "*  X5\tOverall Height \n",
    "* X6\tOrientation \n",
    "*  X7\tGlazing Area \n",
    "*  X8\tGlazing Area Distribution \n",
    "*  y1\tHeating Load \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Q1:Read the data file in python. Describe data features in terms of type, distribution range and mean values. Plot feature distributions.This step should give you clues about data sufficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.98</td>\n",
       "      <td>514.5</td>\n",
       "      <td>294.0</td>\n",
       "      <td>110.25</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>15.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.90</td>\n",
       "      <td>563.5</td>\n",
       "      <td>318.5</td>\n",
       "      <td>122.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>20.84</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     X1     X2     X3      X4   X5  X6   X7  X8     Y1\n",
       "0  0.98  514.5  294.0  110.25  7.0   2  0.0   0  15.55\n",
       "1  0.98  514.5  294.0  110.25  7.0   3  0.0   0  15.55\n",
       "2  0.98  514.5  294.0  110.25  7.0   4  0.0   0  15.55\n",
       "3  0.98  514.5  294.0  110.25  7.0   5  0.0   0  15.55\n",
       "4  0.90  563.5  318.5  122.50  7.0   2  0.0   0  20.84"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy = pd.read_csv(\"Energy.csv\")\n",
    "energy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>Y1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.00000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.00000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.764167</td>\n",
       "      <td>671.708333</td>\n",
       "      <td>318.500000</td>\n",
       "      <td>176.604167</td>\n",
       "      <td>5.25000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.234375</td>\n",
       "      <td>2.81250</td>\n",
       "      <td>22.307201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.105777</td>\n",
       "      <td>88.086116</td>\n",
       "      <td>43.626481</td>\n",
       "      <td>45.165950</td>\n",
       "      <td>1.75114</td>\n",
       "      <td>1.118763</td>\n",
       "      <td>0.133221</td>\n",
       "      <td>1.55096</td>\n",
       "      <td>10.090196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.620000</td>\n",
       "      <td>514.500000</td>\n",
       "      <td>245.000000</td>\n",
       "      <td>110.250000</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>6.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.682500</td>\n",
       "      <td>606.375000</td>\n",
       "      <td>294.000000</td>\n",
       "      <td>140.875000</td>\n",
       "      <td>3.50000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>1.75000</td>\n",
       "      <td>12.992500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>673.750000</td>\n",
       "      <td>318.500000</td>\n",
       "      <td>183.750000</td>\n",
       "      <td>5.25000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>3.00000</td>\n",
       "      <td>18.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.830000</td>\n",
       "      <td>741.125000</td>\n",
       "      <td>343.000000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>4.00000</td>\n",
       "      <td>31.667500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>808.500000</td>\n",
       "      <td>416.500000</td>\n",
       "      <td>220.500000</td>\n",
       "      <td>7.00000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>5.00000</td>\n",
       "      <td>43.100000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               X1          X2          X3          X4         X5          X6  \\\n",
       "count  768.000000  768.000000  768.000000  768.000000  768.00000  768.000000   \n",
       "mean     0.764167  671.708333  318.500000  176.604167    5.25000    3.500000   \n",
       "std      0.105777   88.086116   43.626481   45.165950    1.75114    1.118763   \n",
       "min      0.620000  514.500000  245.000000  110.250000    3.50000    2.000000   \n",
       "25%      0.682500  606.375000  294.000000  140.875000    3.50000    2.750000   \n",
       "50%      0.750000  673.750000  318.500000  183.750000    5.25000    3.500000   \n",
       "75%      0.830000  741.125000  343.000000  220.500000    7.00000    4.250000   \n",
       "max      0.980000  808.500000  416.500000  220.500000    7.00000    5.000000   \n",
       "\n",
       "               X7         X8          Y1  \n",
       "count  768.000000  768.00000  768.000000  \n",
       "mean     0.234375    2.81250   22.307201  \n",
       "std      0.133221    1.55096   10.090196  \n",
       "min      0.000000    0.00000    6.010000  \n",
       "25%      0.100000    1.75000   12.992500  \n",
       "50%      0.250000    3.00000   18.950000  \n",
       "75%      0.400000    4.00000   31.667500  \n",
       "max      0.400000    5.00000   43.100000  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = plt.figure()\n",
    "x = energy.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " __REGRESSION__:\n",
    "LABELS ARE CONTINUOUS VALUES.\n",
    "Here the model is trained to predict a continuous value for each instance.\n",
    "On inputting a feature vector into the model, the trained model is able to predict a continuous value  for  that instance.  \n",
    "\n",
    "__Q2.1: Train a linear regression model on 85 percent of the given dataset, what is the intercept value and coefficient values.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = energy[['X1', 'X2', 'X3', 'X4', 'X5', 'X6', 'X7', 'X8']]\n",
    "y = energy[['Y1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples in training data: 652\n",
      "Number of samples in validation data: 116\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.15, random_state=100)\n",
    "print ('Number of samples in training data:',len(x_train))\n",
    "print ('Number of samples in validation data:',len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a logistic Regression Model..\n",
      "Coefficients: [[ -6.09999091e+01  -1.20592151e+11   1.20592151e+11   2.41184302e+11\n",
      "    4.33188083e+00   1.88790945e-02   2.00671334e+01   2.35574595e-01]]\n",
      "Intercept: [ 75.75107745]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "# Name our logistic regression object\n",
    "LinearRegressionModel = linear_model.LinearRegression()\n",
    "\n",
    "# we create an instance of logistic Regression Classifier and fit the data.\n",
    "print ('Training a logistic Regression Model..')\n",
    "LinearRegressionModel.fit(x_train, y_train)\n",
    "y_train_pred = LinearRegressionModel.predict(x_train)\n",
    "y_test_pred = LinearRegressionModel.predict(x_test)\n",
    "print('Coefficients:', LinearRegressionModel.coef_)\n",
    "print('Intercept:', LinearRegressionModel.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "#### Q.2.2: Report model performance using 'ROOT MEAN SQUARE' error metric on:  \n",
    "__1. Data that was used for training(Training error)__   \n",
    "__2. On the 15 percent of unseen data (test error) __ \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error: 8.57694489763 Testing Error: 8.27772712612\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "train_rmse = mean_squared_error(y_train, y_train_pred)\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred)\n",
    "print('Training Error:', train_rmse, 'Testing Error:', test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__ Q2.3: Lets us see the effect of amount of data on the performance of prediction model.Use varying amounts of  Training data (100,200,300,400,500,all) to train regression models and report  training error and validation error in each case. Validation data/Test data   is the same as above for  all  these cases.__  \n",
    "\n",
    "Plot error rates vs number of training examples.Comment on the relationshipyou observe in the plot, between the amount of data used to train the model and the validation accuracy of the model.\n",
    "\n",
    "__Hint:__ Use array indexing to choose varying data amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error 6.9491634109 Testing Error: 79.0636990049\n"
     ]
    }
   ],
   "source": [
    "LinearRegressionModel = linear_model.LinearRegression()\n",
    "x_train_100 = x.iloc[0:100,:]\n",
    "y_train_100 = y.head(100)\n",
    "LinearRegressionModel.fit(x_train_100, y_train_100)\n",
    "y_train_pred_100 = LinearRegressionModel.predict(x_train_100)\n",
    "y_test_pred = LinearRegressionModel.predict(x_test)\n",
    "\n",
    "train_rmse = mean_squared_error(y_train_100, y_train_pred_100)\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred)\n",
    "print('Training Error', train_rmse, 'Testing Error:', test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error 6.87483688534 Testing Error: 77.9965754862\n"
     ]
    }
   ],
   "source": [
    "LinearRegressionModel = linear_model.LinearRegression()\n",
    "x_train_200 = x.iloc[0:200,:]\n",
    "y_train_200 = y.head(200)\n",
    "LinearRegressionModel.fit(x_train_200, y_train_200)\n",
    "y_train_pred_200 = LinearRegressionModel.predict(x_train_200)\n",
    "y_test_pred = LinearRegressionModel.predict(x_test)\n",
    "\n",
    "train_rmse = mean_squared_error(y_train_200, y_train_pred_200)\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred)\n",
    "print('Training Error', train_rmse, 'Testing Error:', test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error 7.11325122622 Testing Error: 36.5033093621\n"
     ]
    }
   ],
   "source": [
    "LinearRegressionModel = linear_model.LinearRegression()\n",
    "x_train_300 = x.iloc[0:300,:]\n",
    "y_train_300 = y.head(300)\n",
    "LinearRegressionModel.fit(x_train_300, y_train_300)\n",
    "y_train_pred_300 = LinearRegressionModel.predict(x_train_300)\n",
    "y_test_pred = LinearRegressionModel.predict(x_test)\n",
    "\n",
    "train_rmse = mean_squared_error(y_train_300, y_train_pred_300)\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred)\n",
    "print('Training Error', train_rmse, 'Testing Error:', test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error 8.26707234968 Testing Error: 11.5576597351\n"
     ]
    }
   ],
   "source": [
    "LinearRegressionModel = linear_model.LinearRegression()\n",
    "x_train_400 = x.iloc[0:400,:]\n",
    "y_train_400 = y.head(400)\n",
    "LinearRegressionModel.fit(x_train_400, y_train_400)\n",
    "y_train_pred_400 = LinearRegressionModel.predict(x_train_400)\n",
    "y_test_pred = LinearRegressionModel.predict(x_test)\n",
    "\n",
    "train_rmse = mean_squared_error(y_train_400, y_train_pred_400)\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred)\n",
    "print('Training Error', train_rmse, 'Testing Error:', test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error 8.7627346608 Testing Error: 9.4596559659\n"
     ]
    }
   ],
   "source": [
    "LinearRegressionModel = linear_model.LinearRegression()\n",
    "x_train_500 = x.iloc[0:500,:]\n",
    "y_train_500 = y.head(500)\n",
    "LinearRegressionModel.fit(x_train_500, y_train_500)\n",
    "y_train_pred_500 = LinearRegressionModel.predict(x_train_500)\n",
    "y_test_pred = LinearRegressionModel.predict(x_test)\n",
    "\n",
    "train_rmse = mean_squared_error(y_train_500, y_train_pred_500)\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred)\n",
    "print('Training Error', train_rmse, 'Testing Error:', test_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error 8.51989250663 Testing Error: 8.17136398311\n"
     ]
    }
   ],
   "source": [
    "LinearRegressionModel = linear_model.LinearRegression()\n",
    "x_train_all = x\n",
    "y_train_all = y\n",
    "LinearRegressionModel.fit(x_train_all, y_train_all)\n",
    "y_train_pred_all = LinearRegressionModel.predict(x_train_all)\n",
    "y_test_pred = LinearRegressionModel.predict(x_test)\n",
    "\n",
    "train_rmse = mean_squared_error(y_train_all, y_train_pred_all)\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred)\n",
    "print('Training Error', train_rmse, 'Testing Error:', test_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__CLASSIFICATION__:\n",
    "LABELS ARE DISCRETE VALUES.\n",
    "Here the model is trained to classify each instance into a set of predefined  discrete classes.\n",
    "On inputting a feature vector into the model, the trained model is able to predict a  class of that instance. You can also output the probabilities of an instance belnging to a class.  \n",
    "\n",
    "__ Q 3.1:  Bucket values of 'y1' i.e 'Heating Load'  from the original dataset into 3 classes:__ \n",
    "\n",
    "0: 'Low' ( < 15),   \n",
    "1: 'Medium'  (15-30),   \n",
    "2: 'High'  (>30)\n",
    "\n",
    "This converts the given dataset  into a classification problem, classes being, Heating load is: *low, medium or high*. Use this datset with transformed 'heating load' for creating a  logistic regression classifiction model that predicts heating load type of a building. Use test-train split ratio of 0.15.  \n",
    "\n",
    "*Report training and test accuracies and  confusion matrices.*\n",
    "\n",
    "\n",
    "**HINT:** Use pandas.cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy 0.773006134969 Testing Accuracy: 0.76724137931\n",
      "Training Confusion Matrix: \n",
      " [[140   0  35]\n",
      " [  0 244   1]\n",
      " [ 41  71 120]] \n",
      " Testing Confusion Matrix: \n",
      " [[20  0  6]\n",
      " [ 0 40  0]\n",
      " [ 9 12 29]]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "y_new = y['Y1']\n",
    "y_new = pd.cut(y_new, [0, 15, 30, 45], labels=[\"Low\", \"Medium\", \"High\"])\n",
    "y_new = y_new.to_frame()\n",
    "x_train, x_test, y_new_train, y_new_test = train_test_split(x, y_new, test_size=0.15, random_state=100)\n",
    "LogisticRegressionModel = linear_model.LogisticRegression()\n",
    "LogisticRegressionModel.fit(x_train, y_new_train)\n",
    "y_new_train_pred = LogisticRegressionModel.predict(x_train)\n",
    "y_new_test_pred = LogisticRegressionModel.predict(x_test)\n",
    "train_accuracy = accuracy_score(y_new_train, y_new_train_pred)\n",
    "test_accuracy = accuracy_score(y_new_test, y_new_test_pred)\n",
    "print('Training Accuracy', train_accuracy, 'Testing Accuracy:', test_accuracy)\n",
    "train_cf = confusion_matrix(y_new_train, y_new_train_pred)\n",
    "test_cf = confusion_matrix(y_new_test, y_new_test_pred)\n",
    "print('Training Confusion Matrix:', '\\n', train_cf, '\\n', 'Testing Confusion Matrix:', '\\n', test_cf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ Q3.2: One of the preprocessing steps in Data science is Feature Scaling i.e getting all our data on the same scale by setting same  Min-Max of feature values. This makes training less sensitive to the scale of features . Scaling is important in algorithms that use distance based classification, SVM or K means or involve gradient descent optimization.If we  Scale features in the range [0,1] it is called unity based normalization.__\n",
    "\n",
    "__Perform unity based normalization on the above dataset and train the model again, compare model performance in training and validation with your previous model.__  \n",
    "\n",
    "refer:http://scikit-learn.org/stable/modules/preprocessing.html#preprocessing-scaler  \n",
    "more at: https://en.wikipedia.org/wiki/Feature_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error: 0.00623261874897 Testing Error 0.00630161185159\n"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_train_minmax = min_max_scaler.fit_transform(x_train)\n",
    "y_train_minmax = min_max_scaler.fit_transform(y_train)\n",
    "x_test_minmax = min_max_scaler.fit_transform(x_test)\n",
    "y_test_minmax = min_max_scaler.fit_transform(y_test)\n",
    "LinearRegressionModel.fit(x_train_minmax, y_train_minmax)\n",
    "y_train_minmax_pred = LinearRegressionModel.predict(x_train_minmax)\n",
    "y_test_minmax_pred = LinearRegressionModel.predict(x_test_minmax)\n",
    "train_minmax_rmse = mean_squared_error(y_train_minmax, y_train_minmax_pred)\n",
    "test_minmax_rmse = mean_squared_error(y_test_minmax, y_test_minmax_pred)\n",
    "print('Training Error:', train_minmax_rmse, 'Testing Error', test_minmax_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__ 1. Read __`diabetesdata.csv`__ file into a pandas dataframe. Analyze the data features, check for NaN values. \n",
    "About the data: __\n",
    "\n",
    "1. __TimesPregnant__: Number of times pregnant \n",
    "2. __glucoseLevel__: Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. __BP__: Diastolic blood pressure (mm Hg)  \n",
    "5. __insulin__: 2-Hour serum insulin (mu U/ml) \n",
    "6. __BMI__: Body mass index (weight in kg/(height in m)^2) \n",
    "7. __pedigree__: Diabetes pedigree function \n",
    "8. __Age__: Age (years) \n",
    "9. __IsDiabetic__: 0 if not diabetic or 1 if diabetic) \n",
    "\n",
    "__ 2. Preprocess data to replace NaN values in a feature(if any) using mean of the feature.  \n",
    "Train  logistic regression, SVM, perceptron, kNN, xgboost and random forest models using this preprocessed data with 20% test split.Report training and test accuracies.__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimesPregnant</th>\n",
       "      <th>glucoseLevel</th>\n",
       "      <th>BP</th>\n",
       "      <th>insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Pedigree</th>\n",
       "      <th>Age</th>\n",
       "      <th>IsDiabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>40</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TimesPregnant  glucoseLevel  BP  insulin   BMI  Pedigree   Age  IsDiabetic\n",
       "0              6         148.0  72        0  33.6     0.627  50.0           1\n",
       "1              1           NaN  66        0  26.6     0.351  31.0           0\n",
       "2              8         183.0  64        0  23.3     0.672   NaN           1\n",
       "3              1           NaN  66       94  28.1     0.167  21.0           0\n",
       "4              0         137.0  40      168  43.1     2.288  33.0           1"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes = pd.read_csv('diabetesdata.csv')\n",
    "diabetes_orig = diabetes\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__3. What is the  ratio of diabetic persons in 3 equirange bands of 'BMI' and 'Pedigree' in the provided dataset.__\n",
    "\n",
    " __Convert these features - 'BP','insulin','BMI' and 'Pedigree'   into categorical values by mapping different bands of values of these features to integers 0,1,2.__  \n",
    " \n",
    "HINT: USE pd.cut with bin=3 to create 3 bins\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimesPregnant</th>\n",
       "      <th>glucoseLevel</th>\n",
       "      <th>BP</th>\n",
       "      <th>insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Pedigree</th>\n",
       "      <th>Age</th>\n",
       "      <th>IsDiabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TimesPregnant  glucoseLevel BP insulin BMI Pedigree   Age  IsDiabetic\n",
       "0              6         148.0  1       0   1        0  50.0           1\n",
       "1              1           NaN  1       0   1        0  31.0           0\n",
       "2              8         183.0  1       0   1        0   NaN           1\n",
       "3              1           NaN  1       0   1        0  21.0           0\n",
       "4              0         137.0  0       0   1        2  33.0           1"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes['BP'] = pd.cut(diabetes['BP'], 3, labels=[0, 1, 2])\n",
    "diabetes['insulin'] = pd.cut(diabetes['insulin'], 3, labels=[0, 1, 2])\n",
    "diabetes['BMI'] = pd.cut(diabetes['BMI'], 3, labels=[0, 1, 2])\n",
    "diabetes['Pedigree'] = pd.cut(diabetes['Pedigree'], 3, labels=[0, 1, 2])\n",
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "__4. Now consider the original dataset again, instead of generalizing the NAN values with the mean of the feature we will try assigning values to NANs based on some hypothesis. For example for age we assume that the relation between BMI and BP of people is a reflection of the age group.We can have 9 types of BMI and BP relations and our aim is to find the median age of each of that group:__\n",
    "\n",
    "Your Age guess matrix will look like this:  \n",
    "\n",
    "| BMI | 0       | 1      | 2  |\n",
    "|-----|-------------|------------- |----- |\n",
    "| BP  |             |              |      |\n",
    "| 0   | a00         | a01          | a02  |\n",
    "| 1   | a10         | a11          | a12  |\n",
    "| 2   | a20         | a21          |  a22 |\n",
    "\n",
    "\n",
    "__Create a guess_matrix  for NaN values of *'Age'* ( using 'BMI' and 'BP')  and  *'glucoseLevel'*  (using 'BP' and 'Pedigree') for the given dataset and assign values accordingly to the NaNs in 'Age' or *'glucoseLevel'* .__\n",
    "\n",
    "\n",
    "Refer to how we guessed age in the titanic notebook in the class.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess_Age table:\n",
      " [[24 29 33]\n",
      " [25 29 32]\n",
      " [55 37 31]]\n"
     ]
    }
   ],
   "source": [
    "guess_ages = np.zeros((3,3), dtype=int)\n",
    "\n",
    "for idx,dataset in enumerate(diabetes):\n",
    "    for i in range(0, 3):\n",
    "        for j in range(0,3):\n",
    "            guess_df = diabetes[(diabetes.BP == i)&(diabetes.BMI == j)]['Age'].dropna()\n",
    "\n",
    "            # Extract the median age for this group\n",
    "            # (less sensitive) to outliers\n",
    "            age_guess = guess_df.median()\n",
    "          \n",
    "            # Convert random age float to int\n",
    "            guess_ages[i,j] = int(age_guess)\n",
    "    \n",
    "    for i in range(0, 3):\n",
    "        for j in range(0, 3):\n",
    "            diabetes.loc[ (diabetes.Age.isnull()) & (diabetes.BP == i) & (diabetes.BMI == j),\\\n",
    "                    'Age'] = guess_ages[i,j]\n",
    "\n",
    "    diabetes['Age'] = diabetes['Age'].astype(int)\n",
    "print('Guess_Age table:\\n',guess_ages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guess_glucoseLevel table:\n",
      " [[115 127 137]\n",
      " [112 115 149]\n",
      " [133 129 159]]\n"
     ]
    }
   ],
   "source": [
    "guess_gl = np.zeros((3,3), dtype=int)\n",
    "\n",
    "for idx,dataset in enumerate(diabetes):\n",
    "    for i in range(0, 3):\n",
    "        for j in range(0,3):\n",
    "            guess_df = diabetes[(diabetes.BP == i)&(diabetes.Pedigree == j)]['glucoseLevel'].dropna()\n",
    "\n",
    "            # Extract the median age for this group\n",
    "            # (less sensitive) to outliers\n",
    "            gl_guess = guess_df.median()\n",
    "          \n",
    "            # Convert random age float to int\n",
    "            guess_gl[i,j] = int(gl_guess)\n",
    "    \n",
    "    for i in range(0, 3):\n",
    "        for j in range(0, 3):\n",
    "            diabetes.loc[ (diabetes.glucoseLevel.isnull()) & (diabetes.BP == i) & (diabetes.Pedigree == j),\\\n",
    "                    'glucoseLevel'] = guess_gl[i,j]\n",
    "\n",
    "    diabetes['glucoseLevel'] = diabetes['glucoseLevel'].astype(int)\n",
    "print('Guess_glucoseLevel table:\\n',guess_gl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "__5. Now, convert 'glucoseLevel' and 'Age' features also to categorical variables of 5 categories each.__\n",
    "\n",
    "__Use this dataset (with all features in categorical form) to train perceptron, logistic regression and random forest models using 20% test split. Report training and test accuracies.__\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TimesPregnant</th>\n",
       "      <th>glucoseLevel</th>\n",
       "      <th>BP</th>\n",
       "      <th>insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Pedigree</th>\n",
       "      <th>Age</th>\n",
       "      <th>IsDiabetic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   TimesPregnant glucoseLevel BP insulin BMI Pedigree Age  IsDiabetic\n",
       "0              6            3  1       0   1        0   2           1\n",
       "1              1            2  1       0   1        0   0           0\n",
       "2              8            4  1       0   1        0   0           1\n",
       "3              1            2  1       0   1        0   0           0\n",
       "4              0            3  0       0   1        2   0           1"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Training Accuracy: 0.648208469055 Perceptron Testing Accuracy 0.662337662338\n",
      "Logistic Regression Training Accuracy: 0.750814332248 Logistic Regression Testing Accuracy 0.750814332248\n",
      "Random Forest Training Accuracy: 0.892508143322 Random Forest Testing Accuracy 0.681818181818\n"
     ]
    }
   ],
   "source": [
    "diabetes['Age'] = pd.cut(diabetes['Age'], 5, labels=[0, 1, 2, 3, 4])\n",
    "diabetes['glucoseLevel'] = pd.cut(diabetes['glucoseLevel'], 5, labels=[0, 1, 2, 3, 4])\n",
    "diabetes_x = diabetes[['TimesPregnant', 'glucoseLevel', 'BP', 'insulin', 'BMI', 'Pedigree', 'Age']]\n",
    "diabetes_y = diabetes[['IsDiabetic']]\n",
    "x_train, x_test, y_train, y_test = train_test_split(diabetes_x, diabetes_y, test_size = 0.2)\n",
    "PerceptronModel = linear_model.Perceptron()\n",
    "PerceptronModel.fit(x_train, y_train)\n",
    "y_train_pred_perc = PerceptronModel.predict(x_train)\n",
    "y_test_pred_perc = PerceptronModel.predict(x_test)\n",
    "train_accuracy_perc = accuracy_score(y_train, y_train_pred_perc)\n",
    "test_accuracy_perc = accuracy_score(y_test, y_test_pred_perc)\n",
    "print('Perceptron Training Accuracy:', train_accuracy_perc, 'Perceptron Testing Accuracy', test_accuracy_perc)\n",
    "LogisticModel = linear_model.LogisticRegression()\n",
    "LogisticModel.fit(x_train, y_train)\n",
    "y_train_pred_log = LogisticModel.predict(x_train)\n",
    "y_test_pred_log = LogisticModel.predict(x_test)\n",
    "train_accuracy_log = accuracy_score(y_train, y_train_pred_log)\n",
    "test_accuracy_log = accuracy_score(y_train, y_train_pred_log)\n",
    "print('Logistic Regression Training Accuracy:', train_accuracy_log, 'Logistic Regression Testing Accuracy', test_accuracy_log)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RandomForestModel = RandomForestClassifier()\n",
    "RandomForestModel.fit(x_train, y_train)\n",
    "y_train_pred_rf = RandomForestModel.predict(x_train)\n",
    "y_test_pred_rf = RandomForestModel.predict(x_test)\n",
    "train_accuracy_rf = accuracy_score(y_train, y_train_pred_rf)\n",
    "test_accuracy_rf = accuracy_score(y_test, y_test_pred_rf)\n",
    "print('Random Forest Training Accuracy:', train_accuracy_rf, 'Random Forest Testing Accuracy', test_accuracy_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3\n",
    "\n",
    "1. __Derive the expression for the optimal parameters in the linear regression equation, i.e. solve the normal equation for Ordinary Least Squares for the case of Simple Linear Regression, when we only have one input and one output__\n",
    "\n",
    "Given a set of _n_ points $(X_i,Y_i)$ where $Yi$ is dependent on $Xi$ by a linear relation,  find the best-fit line,$$Z_i = {aX_i + b}$$  that minimizes the __sum of squared errors in Y__,i.e: $$minimize \\sum_{i}{(Y_i- Z_i)^2}$$\n",
    "__i. __ Show that $$ intercept \\quad b = \\overline{Y}-  a.\\overline{X}\\quad  and   \\quad slope \\quad a= \\frac{\\sum_{i}(X_i- \\overline{X})\u0001(Y_i- \\overline{Y})}{ \\sum_{i}(X_i- \\overline{X})^2}$$\n",
    "\n",
    "\n",
    " where $\\overline{X}$ and  $\\overline{Y}$ are the averages of the X values and the Y values, respectively.\n",
    " \n",
    "__ ii. __Show that slope _a_ can be written as $ a = r.(S_y /S_x)$ where $S_y$  = the standard deviation of the Y values and $S_x$= the standard deviation of the X values and _r_ is the correlation coefficient.\n",
    "\n",
    "##### Please try to write a nice LateXed version of your answer, and do the derivations of the expressions as nicely as possible\n",
    "\n",
    "\n",
    "_____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "i. To minimize the sum of squared errors, $$\\sum_{i}{(Y_i- Z_i)^2}$$ we know that there must be some relation between the means of both X and Y to their respective values, as the mean value will reduce the square-error the most. We can simply take the partial derivative of this function with respect to a, the parameter which we are trying to find, and we are left with $$\\sum_{i}{(-2X_i*Y_i+(2*a*X_i)^2)}$$ Now we simply seperate and solve for a, which yields $$a = \\frac{\\sum_{i}{(X_i- X)(Y_i- Y)}}{\\sum_{i}{(X_i- X)^2}}$$ The intercept is where the line starts from, and that will simply be $$ b = Y_i - a*X_i$$ after simply rearranging the terms from the linear expression and realizing that $$ Z_i = mean(Y_i)$$ due to the fact that the mean reduces the squared error the most $$\\frac{\\sum_{i}{Y_i}}{n}$$ where n is the total number of terms in Y. \n",
    "\n",
    "ii. r is the correlation coefficient which measures how strong the relationship between the X and Y values are. However, this value is regularized to be between -1 and 1, and thus to account for spread given that the data itself is most probably not regularized, we must scale the correlation coefficient r back up by the standard deviation of the slope which we divided the correlation by earlier to get r, which is indeed $$\\frac{S_y}{S_x}$$ Putting these 2 together and rescaling r back up, we get that the slope is equivalent to $$ r * \\frac{S_y}{S_x}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two Extra Credit Points: Fun with Webscraping & Text manipulation\n",
    "### (Mandatory for Grad students!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class='alert alert-info'> `NOTE:` **If you are a Graduate Section student (enrolled in 290), the Extra Credit Questions are mandatory.**</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1. Statistics in Presidential Debates\n",
    "\n",
    "Your first task is to scrape Presidential Debates from the Commission of Presidential Debates website: http://www.debates.org/index.php?page=debate-transcripts.\n",
    "\n",
    "To do this, you are not allowed to manually look up the URLs that you need, instead you have to scrape them. The root url to be scraped is the one listed above, namely: http://www.debates.org/index.php?page=debate-transcripts\n",
    "\n",
    "\n",
    "1. By using `requests` and `BeautifulSoup` find all the links / URLs on the website that links to transcriptions of **First Presidential Debates** from the years [2012, 2008, 2004, 2000, 1996, 1988, 1984, 1976, 1960]. In total you should find 9 links / URLs tat fulfill this criteria.\n",
    "2. When you have a list of the URLs your task is to create a Data Frame with some statistics (see example of output below):\n",
    "    1. Scrape the title of each link and use that as the column name in your Data Frame. \n",
    "    2. Count how long the transcript of the debate is (as in the number of characters in transcription string). Feel free to include `\\` characters in your count, but remove any breakline characters, i.e. `\\n`. You will get credit if your count is +/- 10% from our result.\n",
    "    3. Count how many times the word **war** was used in the different debates. Note that you have to convert the text in a smart way (to not count the word **warranty** for example, but counting **war.**, **war!**, **war,** or **War** etc.\n",
    "    4. Also scrape the most common used word in the debate, and write how many times it was used. Note that you have to use the same strategy as in 3 in order to do this.\n",
    "    \n",
    "**Tips:**\n",
    "\n",
    "___\n",
    "\n",
    "In order to solve question 3 and 4 above it can be useful to work with Regular Expressions and explore methods on strings like `.strip(), .replace(), .find(), .count(), .lower()` etc. Both are very powerful tools to do string processing in Python. To count common words for example I used a `Counter` object and a Regular expression pattern for only words, see example:\n",
    "\n",
    "```python\n",
    "    from collections import Counter\n",
    "    import re\n",
    "\n",
    "    counts = Counter(re.findall(r\"[\\w']+\", text.lower()))\n",
    "```\n",
    "\n",
    "Read more about Regular Expressions here: https://docs.python.org/3/howto/regex.html\n",
    "    \n",
    "    \n",
    "**Example output of all of the answers to EC Question 1:**\n",
    "\n",
    "\n",
    "![pres_stats](https://github.com/ikhlaqsidhu/data-x/raw/master/x-archive/misc/hw2_imgs_spring2018/president_stats.png)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "----\n",
    "\n",
    ".\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \n",
    "## 2. Download and read in specific line from many data sets\n",
    "\n",
    "Scrape the first 27 data sets from this URL http://people.sc.fsu.edu/~jburkardt/datasets/regression/ (i.e.`x01.txt` - `x27.txt`). Then, save the 5th line in each data set, this should be the name of the data set author (get rid of the `#` symbol, the white spaces and the comma at the end). \n",
    "\n",
    "Count how many times (with a Python function) each author is the reference for one of the 27 data sets. Showcase your results, sorted, with the most common author name first and how many times he appeared in data sets. Use a Pandas DataFrame to show your results, see example.\n",
    "\n",
    "**Example output of the answer EC Question 2:**\n",
    "\n",
    "![author_stats](https://github.com/ikhlaqsidhu/data-x/raw/master/x-archive/misc/hw2_imgs_spring2018/data_authors.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "data-x"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nteract": {
   "version": "0.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
